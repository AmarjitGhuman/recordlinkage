{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced indexing\n",
    "\n",
    "The ``recordlinkage`` module contains several build in indexing algorithms like *full indexing*, *blocking* and *sorted neighbourhood indexing*. Sometimes, these indexing methods are not sufficient. With the ``recordlinkage`` module, it is very easy to implement your own indexing algorithms. In this example, we will show how you can implement your own indexing algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the module and two sample datasets. Also ``numpy`` and ``pandas`` is used for this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "import recordlinkage\n",
    "from recordlinkage.datasets import load_censusA, load_censusB\n",
    "\n",
    "dfA = load_censusA()\n",
    "dfB = load_censusB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the class ``Pairs`` to make the record pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcl = recordlinkage.Pairs(dfA, dfB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, nothing changed. To make a custom indexing algorithm, we have to make a function that does the work for us. In the following example, a random indexing algorithm is made. The algorithm makes record pairs where each record in the record pair in sampled randomly of dataframe ``dfA`` or ``dfB``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomindex(A, B, N_pairs):\n",
    "\n",
    "    random_index_A = numpy.random.choice(A.index.values, N_pairs)\n",
    "    random_index_B = numpy.random.choice(B.index.values, N_pairs)\n",
    "\n",
    "    index = pandas.MultiIndex.from_tuples(zip(random_index_A, random_index_B), names=[A.index.name, B.index.name])\n",
    "\n",
    "    return index.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes the two dataframes ``A`` and ``B`` as input arguments. The argument ``N_pairs`` defines the number of maximum number of record pairs returned. The lines  \n",
    "```\n",
    "random_index_A = np.random.choice(A.index.values, N_pairs)\n",
    "random_index_B = np.random.choice(B.index.values, N_pairs)\n",
    "```\n",
    "are used to sample random indices from both DataFrames. Note that the DataFrames ``A`` and ``B`` are ``pandas.Dataframes``, so we can make advantage of that. In the next line, \n",
    "```\n",
    "index = pd.MultiIndex.from_tuples(zip(random_index_A, random_index_B), names=[A.index.name, B.index.name])\n",
    "```\n",
    "we make a ``pandas.MultiIndex``. See http://pandas.pydata.org/pandas-docs/stable/advanced.html for more details about making and using a MultiIndex. \n",
    "The function returns \n",
    "```\n",
    "index.drop_duplicates()\n",
    "```\n",
    "The duplicates are dropped (so we may not return exactly ``N_pairs``). This is because the MultiIndex has to be unique (we are not going to compare the same record pairs more than once in the comparison step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function ``randomindex``, it is possible to make record pairs directly. Just by calling ``randomindex(dfA, dfB, 1000)``. In that case, it is not possible to use the other build methods in the ``Pairs`` class. Therefore, we can call the following method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_record_pairs = pcl.index(randomindex, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of random record pairs is equal or slightly less than 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(random_record_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing with large files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the input files are very large. In that case, it can be hard to make an index without running out of memory in the indexing step or in the comparing step. ``recordlinkage`` has a method to deal with large files. It is fast, although is not primary developed to be fast. SQL databases may outperform this method. It is especially developed for the useability.\n",
    "The idea was to spllit the input files into small blocks. For each block the record pairs are computed. Then iterate over the blocks. Consider full indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.indexes.multi.MultiIndex'>\n",
      "250000\n",
      "<class 'pandas.indexes.multi.MultiIndex'>\n",
      "250000\n",
      "<class 'pandas.indexes.multi.MultiIndex'>\n",
      "250000\n",
      "<class 'pandas.indexes.multi.MultiIndex'>\n",
      "250000\n"
     ]
    }
   ],
   "source": [
    "pcl_blocks = recordlinkage.Pairs(dfA, dfB, chunks=(500,500))\n",
    "\n",
    "for index_block in pcl_blocks.full():\n",
    "    \n",
    "    # Index returned\n",
    "    print(type(index_block))\n",
    "\n",
    "    # Length of index block\n",
    "    print(len(index_block))\n",
    "    \n",
    "    # Your analysis here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunks of 500x500 result in four iterations (both files contain 1000 records). Because "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
